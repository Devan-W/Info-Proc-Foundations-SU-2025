{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Description (AD) Text Analysis Prep Tool\n",
        "\n",
        "This tool will help you prepare an audio description (AD) dataset for analysis of words spoken in media file.\n",
        "\n",
        "A notable classification in analyzing the words spoken in an AD media is whether a word is or is not a recitation of credits. Reading credits of a film may be important to properly translating the visual experience to the aural experience for AD users, but the words chosen in that recitation are far less interesting to analyze than the other, creative choices in the AD. Perhaps your analysis would benefit from filtering out these credit recitations. Additionally, the WhisperX transcription process labels distinct speakers of the media file. Knowing which speaker speaks credits can serve as a useful indicator of that speaker being the AD voice - since it would be very rare for a character in the narrative to recite the credits like AD does.\n",
        "\n",
        "This project has 2 main modules:\n",
        "\n",
        "1.   **Module 1: Transcribe a mediafile with WhisperX**\n",
        "This is helpful if you don't yet have a dataset of words spoken in a media file of interest, and also don't yet have word level timestamps or speaker identification. Caption files bundle words in caption blocks and this timing may not be precise enough for certain analysis. Additionally, caption and transcript files may not include speaker identification, which would prevent analysis in comparing what words are used in the AD relative to non-AD words. The outputs of WhisperX will write to the same directory as your media file. Module 1 Includes outputs of transcript (txt), caption file (srt) and full data including word level timestamps (json).\n",
        "\n",
        "2.   **Module 2: Give words a 'Credit Score'**\n",
        "This module will assess each run of words (named by run_id) from the same speaker ID as assigned by whisperX. A weighted score will be given to each run_id and the highest score (1.00 being a perfect score) is considered the most likely candidate to be the run of words which is reciting the credits. Filtering of this run and other runs could later be applied to analysis. The output of Module 2 is a csv and could be leveraged as a classified version of the Module 1 json dataset. These tools in Module 2 assume English language is both the predominant language of the AD and the media file.\n",
        "\n"
      ],
      "metadata": {
        "id": "IHaV-TFSGjmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1: Transcribe a mediafile with WhisperX\n",
        "\n",
        "Credit to Elle Wang for video tutorial on running WhisperX in Google Colab: https://www.youtube.com/watch?v=1z0aHkFbD8E\n",
        "\n",
        "WARNING: If running Module 1 (WhisperX), change runtime in Google Colab to T4 GPU. Go to Runtime > Change Runtime Type and select T4 GPU. WhisperX needs much more power than the default CPU setting. If you do not change this before you start running cells in Module 1, you'll loose that work when changing runtime and have to redo those cells. If simply running Module 2, CPU runtime is best to conserve Colab usage limits.\n",
        "\n",
        "Module 1 requires an access token be generated on Hugging Face (aka hf). Create an account on hf, and follow instructions for creating an access token to include in the provided code. Read token is sufficient:\n",
        "https://huggingface.co/docs/hub/en/security-tokens\n",
        "\n",
        "Also while on hf with an account, your account will need to accept the usage terms of 2 models on that platform. The usage of the models is free, though you do need to accept the terms before Module 1 (whisperX) will run correctly.\n",
        "\n",
        "Accept the terms of each on their respective landing pages before whisperX can pull them via your hf access token\n",
        "\n",
        "https://huggingface.co/pyannote/segmentation-3.0\n",
        "\n",
        "https://huggingface.co/pyannote/speaker-diarization-3.1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PdFPUdiHK1ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 1: Kernel 1 ##\n",
        "## This kernel prepares a directory and media file to run on WhisperX ##\n",
        "\n",
        "## You'll have option to 1. Use Google Drive or 2. Upload into Colab ##\n",
        "## Choosing Google Drive will prompt for permission. Then ask for the directory path to the folder with your file ##\n",
        "## Choosing Upload option will not save the files outside of the Colab session. Aka, save WhisperX outputs! ##\n",
        "\n",
        "import os\n",
        "from google.colab import files, drive\n",
        "\n",
        "# Step 1: Prompt user for storage option\n",
        "file_choice = input(\"Choose an option:\\n1 - Connect to Google Drive\\n2 - Upload a file to sample_data\\nEnter 1 or 2: \")\n",
        "\n",
        "if file_choice == '1':\n",
        "    # Step 2a: Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted.\")\n",
        "\n",
        "    # Step 2b: Ask for directory path\n",
        "    example_path = '/content/drive/MyDrive/your_folder_name'\n",
        "    drive_path = input(f\"Enter the full path to your Google Drive folder (e.g., {example_path}): \")\n",
        "\n",
        "    if os.path.exists(drive_path):\n",
        "        os.chdir(drive_path)\n",
        "        print(f\"Changed directory to: {drive_path}\")\n",
        "        # Step 2c: store file list in this directory to variable file_list and print that variable\n",
        "        file_list = os.listdir()\n",
        "        print(\"Files in this directory:\", file_list)\n",
        "\n",
        "    else:\n",
        "        print(\"That path doesn't exist. Please double-check and try again.\")\n",
        "\n",
        "elif file_choice == '2':\n",
        "    # Upload file\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Save to /content/media_files (or any subfolder you prefer)\n",
        "    media_dir = '/content/media_files'\n",
        "    os.makedirs(media_dir, exist_ok=True)\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "      dest_path = os.path.join(media_dir, filename)\n",
        "      os.rename(filename, dest_path)\n",
        "      print(f\"Saved {filename} to {dest_path}\")\n",
        "\n",
        "    # Step 3b: Change to sample_data directory\n",
        "    os.chdir(media_dir)\n",
        "    print(\"Changed directory to\", media_dir)\n",
        "\n",
        "    # Step 3c: store file list in this directory to variable file_list and print that variable\n",
        "    file_list = os.listdir()\n",
        "    print(\"Files in this directory:\", file_list)\n",
        "\n",
        "else:\n",
        "    print(\"Invalid choice. Please enter 1 or 2.\")\n"
      ],
      "metadata": {
        "id": "ki5dKgwhrxWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 1: Kernel 2 ##\n",
        "## Prepare your variables for Kernel 3 (WhisperX) ##\n",
        "\n",
        "## Insert your hf token in the placeholder [add_hf_token_here] ##\n",
        "## Pick the file name in the sample_data OR the folder (aka directory) you\n",
        "## indicated in the previous kernel of %cd. ##\n",
        "## Note: WhisperX will accept audio files or video files like mp4 or mp3 ##\n",
        "\n",
        "import getpass\n",
        "\n",
        "# Step 1: Securely prompt for Hugging Face token\n",
        "hf_token = getpass.getpass(\"Enter your Hugging Face token (input hidden): \")\n",
        "\n",
        "# Step 2: Display file list and prompt for selection\n",
        "print(\"\\nAvailable files:\")\n",
        "for i, filename in enumerate(file_list):\n",
        "    print(f\"{i + 1}: {filename}\")\n",
        "\n",
        "file_index = int(input(\"\\nSelect a file by number: \")) - 1\n",
        "\n",
        "# Validate selection\n",
        "if file_index < 0 or file_index >= len(file_list):\n",
        "    print(\"Invalid selection.\")\n",
        "else:\n",
        "    selected_file = file_list[file_index]\n",
        "    print(f\"\\n Running WhisperX on: {selected_file}\")"
      ],
      "metadata": {
        "id": "abUwWKEavVem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 1: Kernel 3 ##\n",
        "## This is your kernel to run WhisperX. ##\n",
        "\n",
        "## WhisperX settings: ##\n",
        "## --model large-v2 is good for this task ##\n",
        "## --chunk_size 6 is good for this task ##\n",
        "## --diarize is a flag to include this phase of the process and\n",
        "## is very helpful for preparing AD dataset for analysis ##\n",
        "\n",
        "\n",
        "## Install all tools for WhisperX. This will take a minute or 2 ##\n",
        "## Remember to change runtime in Google Colab to T4 GPU for best running of WhisperX ##\n",
        "\n",
        "!pip install whisperx\n",
        "\n",
        "!pip3 install -U huggingface_hub\n",
        "\n",
        "!apt install libcudnn8 libcudnn8-dev -y\n",
        "\n",
        "## Run the WhisperX code! This will take a few minutes ##\n",
        "!whisperx --model large-v2 --chunk_size 6 --diarize --hf_token {hf_token} \"{selected_file}\"\n",
        "\n",
        "## OUTPUT EXPLAINATION ##\n",
        "## The output files will write to the same location as the input media file. ##\n",
        "## Each will have the same file name as the input file but with different extensions. ##\n",
        "## Among the outputs: SRT is a caption file. TXT is a transcript file (without timecodes).\n",
        "## JSON is the full dataset with each word timestamped and assigned a speaker value as \"SPEAKER ##\" ##"
      ],
      "metadata": {
        "id": "51lHnDjpykMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 1: Kernel 4 ##\n",
        "## Optional check of the WhisperX json output and save as CSV ##\n",
        "\n",
        "## To manipulate and analyze the transcription provided by WhisperX, ##\n",
        "## Note: this will only work for a json in the same directory selected earlier ##\n",
        "## (either Google drive folder or sample_data in Google Colab) ##\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "## Input function asks the user for the file name to open in the later functions of the kernel. ##\n",
        "json_file_name = input(\"Please enter the JSON file name (e.g., ADxPD_Plan9_Mix.json): \")\n",
        "\n",
        "## change file name below to json file name inside the single quotes ##\n",
        "with open(json_file_name, 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "## This block interprets the json data structure to prep for the dataframe ##\n",
        "all_words = []\n",
        "for segment in data['segments']:\n",
        "  for word_info in segment['words']:\n",
        "    all_words.append(word_info)\n",
        "\n",
        "## df0 will be the name of the dataframe native to the json file. ##\n",
        "## Module 2 will analyze df0 but also add to it, ##\n",
        "## resulting in modified dataframes of names df1, df2, etc. ##\n",
        "df0 = pd.DataFrame(all_words)\n",
        "\n",
        "## This line defines the data types of each column in the dataframe ##\n",
        "df0 = df0.astype({'word': str, 'start': float, 'end': float, 'score': float, 'speaker': str})\n",
        "\n",
        "## This line updates pandas formating options to display all the decimals of the timecode info from json file ##\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df0.to_csv('{input}.csv', index=False)\n",
        "\n",
        "print(df0)\n"
      ],
      "metadata": {
        "id": "vyykDs5CBOm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: Give words a 'Credit Score'\n",
        "You may be interested in analyzing the words transcribed from your media file. While it is helpful for primary AD users to have any on-screen text read aloud, the recitation of the credits (opening or ending) represents a far different creative process from the other words used in the piece - either AD or non-AD. Knowing if a word is a recitation of credits or not becomes a useful classification for further analysis. Additionally, it's very rare for credits recited or narrated which is not the AD. If attempting to automate the classification of which Speaker is the AD, having a classification of which words are credits would aid this as a second order classification.\n",
        "\n",
        "What follows is a series of tests for runs of words by speaker. WhisperX outputs a transcription of each word in linear order and assigns a speaker id of who spoke that word. A \"run of words by the same speaker\" is an unbroken stretch of words by the same speaker. If at least one word from another speaker label interups a run, then a new run is started. Runs are then given a run_id linearly through the piece to analyze certain properties of each run.\n",
        "\n",
        "The results from each test are weighted and added together to form a 'credit score' - 1 being the top score was acheived by that run_id for all tests. The score closest to 1 can be assumed as the highest likelihood this run is a recitation of credits. This credit score will be stored in a final dataframe but also output to a csv with all columns needed for Module 2 appended to the original dataframe from the whisperX output (df0). Analysis can then proceed using this classification along dimenion of the run_id's credit score."
      ],
      "metadata": {
        "id": "0n0mqDAJ484B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DDWBa8i_MeKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 2: Kernel 1 ##\n",
        "## This kernel prepares a directory and json file to analyze ##\n",
        "## NOTE: If continuing with selections and output from Module 1,\n",
        "## and same session/runtime, then you can skip this kernel. ##\n",
        "\n",
        "## You'll have option to 1. Use Google Drive or 2. Upload into Colab ##\n",
        "## Choosing Google Drive will prompt for permission. Then ask for the directory path to the folder with your file ##\n",
        "## Choosing Upload option will not save the files outside of the Colab session. Aka, save outputs! ##\n",
        "\n",
        "import os\n",
        "from google.colab import files, drive\n",
        "\n",
        "# Step 1: Prompt user for storage option\n",
        "file_choice = input(\"Choose an option:\\n1 - Connect to Google Drive\\n2 - Upload a file to sample_data\\nEnter 1 or 2: \")\n",
        "\n",
        "if file_choice == '1':\n",
        "    # Step 2a: Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted.\")\n",
        "\n",
        "    # Step 2b: Ask for directory path\n",
        "    example_path = '/content/drive/MyDrive/your_folder_name'\n",
        "    drive_path = input(f\"Enter the full path to your Google Drive folder (e.g., {example_path}): \")\n",
        "\n",
        "    if os.path.exists(drive_path):\n",
        "        os.chdir(drive_path)\n",
        "        print(f\"Changed directory to: {drive_path}\")\n",
        "        # Step 2c: store file list in this directory to variable file_list and print that variable\n",
        "        file_list = os.listdir()\n",
        "        print(\"Files in this directory:\", file_list)\n",
        "\n",
        "    else:\n",
        "        print(\"That path doesn't exist. Please double-check and try again.\")\n",
        "\n",
        "elif file_choice == '2':\n",
        "    # Upload file\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Save to /content/media_files (or any subfolder you prefer)\n",
        "    media_dir = '/content/media_files'\n",
        "    os.makedirs(media_dir, exist_ok=True)\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "      dest_path = os.path.join(media_dir, filename)\n",
        "      os.rename(filename, dest_path)\n",
        "      print(f\"Saved {filename} to {dest_path}\")\n",
        "\n",
        "    # Step 3b: Change to sample_data directory\n",
        "    os.chdir(media_dir)\n",
        "    print(\"Changed directory to\", media_dir)\n",
        "\n",
        "    # Step 3c: store file list in this directory to variable file_list and print that variable\n",
        "    file_list = os.listdir()\n",
        "    print(\"Files in this directory:\", file_list)\n",
        "\n",
        "else:\n",
        "    print(\"Invalid choice. Please enter 1 or 2.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "f9b4AY4FMejk",
        "outputId": "83cd834b-6189-4e40-81f2-273a2e3aee4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose an option:\n",
            "1 - Connect to Google Drive\n",
            "2 - Upload a file to sample_data\n",
            "Enter 1 or 2: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0bf708b6-57e9-4c77-bb70-f7de022b25a8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0bf708b6-57e9-4c77-bb70-f7de022b25a8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ADxPD_Plan9_Mix.json to ADxPD_Plan9_Mix.json\n",
            "Saved ADxPD_Plan9_Mix.json to /content/media_files/ADxPD_Plan9_Mix.json\n",
            "Changed directory to /content/media_files\n",
            "Files in this directory: ['ADxPD_Plan9_Mix.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 2: Kernel 2 ##\n",
        "## NOTE: If continuing with selections and output from Module 1,\n",
        "## and same session/runtime, then you can skip this kernel. ##\n",
        "\n",
        "## If you haven't already loaded the json file into a dataframe for this session, ##\n",
        "## you'll need to run this kernel which is a repeat of the final Module 1 kernel. ##\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "json_file_name = input(\"Please enter the JSON file name (e.g., ADxPD_Plan9_Mix.json): \")\n",
        "\n",
        "with open(json_file_name, 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "for segment in data['segments']:\n",
        "  for word_info in segment['words']:\n",
        "    all_words.append(word_info)\n",
        "\n",
        "df0 = pd.DataFrame(all_words)\n",
        "df0 = df0.astype({'word': str, 'start': float, 'end': float, 'score': float, 'speaker': str})\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "\n",
        "print(\"Original DataFrame\")\n",
        "print(df0)"
      ],
      "metadata": {
        "id": "NlT3nPd88shr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add57bae-29e3-4cb5-ce33-0fa1cdcd2e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the JSON file name (e.g., ADxPD_Plan9_Mix.json): ADxPD_Plan9_Mix.json\n",
            "Original DataFrame\n",
            "           word     start       end  score     speaker\n",
            "0             ♪     2.680     8.151  0.901  SPEAKER_10\n",
            "1            In     8.131     8.393  0.797  SPEAKER_10\n",
            "2          bold     8.473     8.695  0.750  SPEAKER_10\n",
            "3     lettering     8.755     9.077  0.852  SPEAKER_10\n",
            "4          over     9.218     9.379  0.944  SPEAKER_10\n",
            "...         ...       ...       ...    ...         ...\n",
            "8800  Ghoulman, 4,689.279 4,689.723  0.601  SPEAKER_10\n",
            "8801       Bela 4,689.743 4,689.925  0.580  SPEAKER_10\n",
            "8802    Lugosi, 4,689.945 4,690.167  0.411  SPEAKER_10\n",
            "8803        and 4,690.389 4,690.530  0.727  SPEAKER_10\n",
            "8804  Criswell. 4,690.571 4,691.115  0.602  SPEAKER_10\n",
            "\n",
            "[8805 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 2: Kernel 3 ##\n",
        "## This kernel contains all of the analysis and dataframe appending for the Credit Score ##\n",
        "\n",
        "# Create df1 as an interation of our original df0, leaving df0 undisturbed by Module 2.\n",
        "# Create run_id, a UID for every stretch of words of the same speaker value.\n",
        "# Use a boolean series indicating where the speaker value changes\n",
        "# from the previous row.\n",
        "df1 = df0.assign(\n",
        " speaker_change_point = df0['speaker'] != df0['speaker'].shift(),\n",
        " run_id = (df0['speaker'] != df0['speaker'].shift()).cumsum()\n",
        ")\n",
        "# Save the df1 to a CSV file\n",
        "# This aids in later analysis using the run_id as primary key\n",
        "df1.to_csv(f'{json_file_name}_run_id.csv', index=False)\n",
        "\n",
        "## CREDIT SCORE Test 1: \"Long, Uninterupted run_id\" ##\n",
        "# Count rows per run_id\n",
        "run_counts = df1.groupby('run_id').size().reset_index(name='run_count')\n",
        "\n",
        "# Get the first speaker value for each run_id\n",
        "speakers = df1.groupby('run_id')['speaker'].first().reset_index()\n",
        "\n",
        "# Merge counts with speaker values\n",
        "run_length_words = run_counts.merge(speakers, on='run_id')\n",
        "\n",
        "# Create a df for this entire Credit Scoring process with run_id as primary key\n",
        "df_creditscores = run_length_words[['run_id', 'run_count']]\n",
        "\n",
        "# Calculate length (in seconds) of each run_id\n",
        "run_length_time = df1.groupby('run_id').agg(\n",
        "    max_end=('end', 'max'),\n",
        "    min_start=('start', 'min')\n",
        ").reset_index()\n",
        "\n",
        "run_length_time['run_length_time'] = run_length_time['max_end'] - run_length_time['min_start']\n",
        "\n",
        "# Merge run_length_time into df_creditscores\n",
        "df_creditscores = df_creditscores.merge(run_length_time[['run_id', 'run_length_time']], on='run_id', how='left')\n",
        "\n",
        "# Multiply both lengths to get a wider distribution of words per time for final \"length\"\n",
        "df_creditscores['run_length_total'] = df_creditscores['run_count'] * df_creditscores['run_length_time']\n",
        "print(\"df_creditscores Test 1 added\")\n",
        "print(df_creditscores[['run_id','run_length_total','run_count','run_length_time']])\n",
        "\n",
        "## CREDIT SCORE Test 2: Typical words from credits ##\n",
        "# Define the list of target words appearing in typical credits recitation\n",
        "target_credit_words = ['by', 'direct', 'produce', 'credit']\n",
        "\n",
        "# Create a regex pattern\n",
        "pattern = '|'.join(target_credit_words)\n",
        "\n",
        "# Find rows where 'word' matches any of the target words (case-insensitive)\n",
        "matches = df1['word'].str.contains(pattern, case=False, na=False)\n",
        "\n",
        "# Count matches per run_id\n",
        "credit_word_count = df1[matches].groupby('run_id').size().reset_index(name='credit_word_count')\n",
        "\n",
        "# Merge into df_creditscores\n",
        "df_creditscores = df_creditscores.merge(credit_word_count, on='run_id', how='left')\n",
        "df_creditscores['credit_word_count'] = df_creditscores['credit_word_count'].fillna(0).astype(int)\n",
        "print(\"df_creditscores Test 2 added\")\n",
        "print(df_creditscores[['run_id','credit_word_count']])\n",
        "\n",
        "## CREDIT SCORE Test 3: Proper Noun count ##\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required NLTK resources (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Group words by run_id\n",
        "run_id_words = df1.groupby('run_id')['word'].apply(list).reset_index()\n",
        "\n",
        "# Function to count proper nouns in a list of words\n",
        "def count_proper_nouns(words):\n",
        "    tokens = [str(w) for w in words]  # Ensure all are strings\n",
        "    tagged = pos_tag(tokens)\n",
        "    return sum(1 for word, tag in tagged if tag in ('NNP', 'NNPS'))\n",
        "\n",
        "# Apply the function to each group\n",
        "run_id_words['proper_noun_count'] = run_id_words['word'].apply(count_proper_nouns)\n",
        "\n",
        "# Merge into df_creditscores\n",
        "df_creditscores = df_creditscores.merge(run_id_words[['run_id', 'proper_noun_count']], on='run_id', how='left')\n",
        "df_creditscores['proper_noun_count'] = df_creditscores['proper_noun_count'].fillna(0).astype(int)\n",
        "print(\"df_creditscores Test 3 added\")\n",
        "print(df_creditscores[['run_id','proper_noun_count']])\n",
        "\n",
        "## CREDIT SCORE Test 4: Labelling the Final Run ##\n",
        "# Identify the maximum run_id\n",
        "max_run_id = df1['run_id'].max()\n",
        "\n",
        "# Add a new column to flag the final run with a 1 and everything else a 0\n",
        "df_creditscores['final_run'] = df_creditscores['run_id'].apply(lambda x: 1 if x == max_run_id else 0)\n",
        "print(\"df_creditscores Test 4 added\")\n",
        "print(df_creditscores[['run_id','final_run']])\n",
        "\n",
        "## CREDIT SCORE Tests aggregation ##\n",
        "# Calculate the maximum value in each test column with a variable value\n",
        "max_run_length = df_creditscores['run_length_total'].max()\n",
        "max_credit_word_count = df_creditscores['credit_word_count'].max()\n",
        "max_proper_noun_count = df_creditscores['proper_noun_count'].max()\n",
        "\n",
        "# Create a new columns with normalized values scaled between 0 and 1\n",
        "df_creditscores['run_length_normalized'] = df_creditscores['run_length_total'] / max_run_length\n",
        "df_creditscores['credit_word_normalized'] = df_creditscores['credit_word_count'] / max_credit_word_count\n",
        "df_creditscores['proper_noun_normalized'] = df_creditscores['proper_noun_count'] / max_proper_noun_count\n",
        "\n",
        "## CREDIT SCORE Test weighting to combine with relative importance of each test ##\n",
        "# Test weights can be adjusted based on specific needs or refinement of analysis\n",
        "# Weights can total to 1.00 if wanting a normalized scoring system\n",
        "df_creditscores['run_credit_score_total'] = (\n",
        "    df_creditscores['run_length_normalized'] * 0.2 +\n",
        "    df_creditscores['credit_word_normalized'] * 0.4 +\n",
        "    df_creditscores['proper_noun_normalized'] * 0.3 +\n",
        "    df_creditscores['final_run'] * 0.2\n",
        ")\n",
        "print(\"df_creditscores Full DataFrame with Credit Score added\")\n",
        "print(df_creditscores)\n",
        "\n",
        "# Sort by 'run_credit_score_total' in descending order and display the top 20\n",
        "top_20 = df_creditscores.sort_values(by='run_credit_score_total', ascending=False).head(20)\n",
        "print(\"Top 20 Credit Scores Sorted in DataFrame\")\n",
        "print(top_20[['run_id','run_credit_score_total']])\n",
        "\n"
      ],
      "metadata": {
        "id": "R1TxUkSfMrmD",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c57007-2d2f-47e5-cb73-302c2a550073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_creditscores Test 1 added\n",
            "     run_id  run_length_total  run_count  run_length_time\n",
            "0         1           748.045         41           18.245\n",
            "1         2         8,578.385        139           61.715\n",
            "2         3        13,249.488        168           78.866\n",
            "3         4           843.359         43           19.613\n",
            "4         5             2.364          3            0.788\n",
            "..      ...               ...        ...              ...\n",
            "517     518            24.876          6            4.146\n",
            "518     519         3,868.716         87           44.468\n",
            "519     520         1,327.326         66           20.111\n",
            "520     521             0.928          2            0.464\n",
            "521     522           398.844         36           11.079\n",
            "\n",
            "[522 rows x 4 columns]\n",
            "df_creditscores Test 2 added\n",
            "     run_id  credit_word_count\n",
            "0         1                  0\n",
            "1         2                  0\n",
            "2         3                  8\n",
            "3         4                  0\n",
            "4         5                  0\n",
            "..      ...                ...\n",
            "517     518                  0\n",
            "518     519                  0\n",
            "519     520                  1\n",
            "520     521                  0\n",
            "521     522                  0\n",
            "\n",
            "[522 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_creditscores Test 3 added\n",
            "     run_id  proper_noun_count\n",
            "0         1                  1\n",
            "1         2                  6\n",
            "2         3                121\n",
            "3         4                  2\n",
            "4         5                  0\n",
            "..      ...                ...\n",
            "517     518                  1\n",
            "518     519                  2\n",
            "519     520                 43\n",
            "520     521                  2\n",
            "521     522                 35\n",
            "\n",
            "[522 rows x 2 columns]\n",
            "df_creditscores Test 4 added\n",
            "     run_id  final_run\n",
            "0         1          0\n",
            "1         2          0\n",
            "2         3          0\n",
            "3         4          0\n",
            "4         5          0\n",
            "..      ...        ...\n",
            "517     518          0\n",
            "518     519          0\n",
            "519     520          0\n",
            "520     521          0\n",
            "521     522          1\n",
            "\n",
            "[522 rows x 2 columns]\n",
            "df_creditscores Credit Score added\n",
            "     run_id  run_count  run_length_time  run_length_total  credit_word_count  \\\n",
            "0         1         41           18.245           748.045                  0   \n",
            "1         2        139           61.715         8,578.385                  0   \n",
            "2         3        168           78.866        13,249.488                  8   \n",
            "3         4         43           19.613           843.359                  0   \n",
            "4         5          3            0.788             2.364                  0   \n",
            "..      ...        ...              ...               ...                ...   \n",
            "517     518          6            4.146            24.876                  0   \n",
            "518     519         87           44.468         3,868.716                  0   \n",
            "519     520         66           20.111         1,327.326                  1   \n",
            "520     521          2            0.464             0.928                  0   \n",
            "521     522         36           11.079           398.844                  0   \n",
            "\n",
            "     proper_noun_count  final_run  run_length_normalized  \\\n",
            "0                    1          0                  0.056   \n",
            "1                    6          0                  0.647   \n",
            "2                  121          0                  1.000   \n",
            "3                    2          0                  0.064   \n",
            "4                    0          0                  0.000   \n",
            "..                 ...        ...                    ...   \n",
            "517                  1          0                  0.002   \n",
            "518                  2          0                  0.292   \n",
            "519                 43          0                  0.100   \n",
            "520                  2          0                  0.000   \n",
            "521                 35          1                  0.030   \n",
            "\n",
            "     credit_word_normalized  proper_noun_normalized  run_credit_score_total  \n",
            "0                     0.000                   0.008                   0.014  \n",
            "1                     0.000                   0.050                   0.144  \n",
            "2                     1.000                   1.000                   0.900  \n",
            "3                     0.000                   0.017                   0.018  \n",
            "4                     0.000                   0.000                   0.000  \n",
            "..                      ...                     ...                     ...  \n",
            "517                   0.000                   0.008                   0.003  \n",
            "518                   0.000                   0.017                   0.063  \n",
            "519                   0.125                   0.355                   0.177  \n",
            "520                   0.000                   0.017                   0.005  \n",
            "521                   0.000                   0.289                   0.293  \n",
            "\n",
            "[522 rows x 11 columns]\n",
            "Top 20 credit scores\n",
            "     run_id  run_credit_score_total\n",
            "2         3                   0.900\n",
            "521     522                   0.293\n",
            "453     454                   0.223\n",
            "136     137                   0.215\n",
            "286     287                   0.202\n",
            "519     520                   0.177\n",
            "449     450                   0.165\n",
            "463     464                   0.160\n",
            "284     285                   0.149\n",
            "1         2                   0.144\n",
            "222     223                   0.142\n",
            "98       99                   0.134\n",
            "168     169                   0.132\n",
            "445     446                   0.101\n",
            "339     340                   0.095\n",
            "296     297                   0.088\n",
            "282     283                   0.087\n",
            "461     462                   0.085\n",
            "350     351                   0.067\n",
            "97       98                   0.066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Module 2 Kernel 4 - Optional ##\n",
        "# Save the Credit Score DataFrame to a CSV file\n",
        "df_creditscores.to_csv(f'{json_file_name}_creditscore.csv', index=False)"
      ],
      "metadata": {
        "id": "iM7NcTW_RlaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}